{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "#import warnings\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import  TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Yelp Review NLP Project </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <strong>This is a machine learning project using a dataset of yelp reviews from Kaggle. (https://www.kaggle.com/c/yelp-recsys-2013). The goal of the project is to examine and visualize the data, and train a model to predict whether a customer review is a good or bad. </strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews =  pd.read_csv('yelp.csv') \n",
    "reviews2 = pd.read_csv('new_yelp_review_2.csv', index_col=0)\n",
    "#reviews2.head()\n",
    "#reviews.head()\n",
    "# The first data set had many more positive reviews so I am adding more negative reviews\n",
    "# from a second dataset\n",
    "#reviews2 = reviews2[reviews2['stars'] == 1]\n",
    "reviews2 = reviews2.iloc[:3000]\n",
    "reviews = reviews.append(reviews2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Examine the head of the dataframe to get an idea of what the data consists of.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>The business_id, review_id, user_id, and date will not be used so those columns can be removed. I'll add a column containing the length of review in characters to have an additional feature to work with. </strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column for review text length\n",
    "reviews['length'] = reviews['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused data columns\n",
    "reviews = reviews.drop(['review_id'], axis=1)\n",
    "reviews = reviews.drop(['business_id'], axis=1)\n",
    "reviews = reviews.drop(['user_id'], axis=1)\n",
    "reviews = reviews.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(['type'], axis=1)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Analyzing the data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Examine the number of reviews for each review length.<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram showing the number of reviews for each length of text\n",
    "fig = px.histogram(reviews, x=\"length\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The majority of reviews are between 0 and 1000 characters\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Compare length of review to star rating </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms that show the number of reviews for each length of text for each sentiment\n",
    "fig = px.histogram(reviews, x=\"length\", color='stars')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>The majority of reviews for all star ratings are between 0 and 1000 characters.</strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Examine the number of star ratings for reviews in the dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot showing the total number of negative and positive reviews in the dataset\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "axes1 = plt.subplot(2,2,1)\n",
    "axes1 = sns.countplot(x='stars', data=reviews)\n",
    "axes1.set_title('Stars')\n",
    "axes1.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "#ax = sns.barplot(x=\"stars\", y=\"stars\", data=reviews, estimator=lambda x: len(x) / len(reviews) * 100)\n",
    "#ax.set(ylabel=\"Percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <strong>The data contains many 1 star reviews and 4-5 star reviews. </stong></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Display the frequency of each review length </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of the distribution of text length\n",
    "length_distro = plt.figure(figsize=(12,8))\n",
    "sns.distplot(reviews['length'], kde=True, bins=25)\n",
    "plt.title('Text Length Distribution')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A heatmap to examine if there is any correlation between the columns of the dataset</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stars = reviews.groupby('stars').mean()\n",
    "\n",
    "\n",
    "# heatmap to look for categories that may have a correlation\n",
    "#stars.corr()\n",
    "\n",
    "#sns.heatmap(stars.corr(),cmap='coolwarm',annot=True)\n",
    "sns.heatmap(reviews.corr(), cmap='coolwarm', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong> The columns in the data that correlate the most are 'cool' and a 'funny'. Since these columns are basically a rating of the review itself, this correlation will not help identify positive or negative reviews. It appears that no columns have much correlation with the star rating. </strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong> For the remainder of the analysis we are going to work with only the 1 star reviews and the 5 star reviews</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews_class = reviews[(reviews.stars==1) | (reviews.stars==5)]\n",
    "reviews_class = reviews_class.iloc[1500:5500]\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "axes1 = plt.subplot(2,2,1)\n",
    "axes1 = sns.countplot(x='stars', data=reviews_class)\n",
    "axes1.set_title('Stars')\n",
    "axes1.set_ylabel('Count')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Descriptive Method - K-means Clustering </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>I attempt to use k-means clustering to find relationships within the text data.\n",
    "   The review text is transformed using TFIDF (term frequency inverse document frequency).\n",
    "    Since we are trying to classify positive and negative reviews 2 clusters will used</strong><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the text data to attemp k-means clustering\n",
    "random_state = 0\n",
    "vector = TfidfVectorizer(stop_words=\"english\")\n",
    "vector.fit(reviews_class.text.values)\n",
    "features = vector.transform(reviews_class.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = MiniBatchKMeans(n_clusters=2, random_state=random_state)\n",
    "clusters.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the dataframe to hold the cluster label\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "reviews_class['cluster_num'] = clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the feature dimension into two dimensions for plotting\n",
    "pca = PCA(n_components=2, random_state=random_state)\n",
    "reduced_features = pca.fit_transform(features.toarray())\n",
    "reduced_cluster_centers = pca.transform(clusters.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <strong>Below is a scatterplot to show the result of clustering.</strong> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of k-means clustering\n",
    "plt.scatter(reduced_features[:,0], reduced_features[:,1], c = clusters.predict(features))\n",
    "plt.scatter(reduced_cluster_centers[:,0], reduced_cluster_centers[:,1], marker='x', s=150, c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <strong>The scatterplot show a lot of overlap in the clusters. Below is homogeneity_score of \n",
    "    the clustering results</strong> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the results of k-means clustering\n",
    "from sklearn.metrics import homogeneity_score\n",
    "homogeneity_score(reviews_class.stars, clusters.predict(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <strong>Ideally a score close to 1 would show effective clustering. The score for the review text\n",
    "    is close to zero which confirms a lot of overlap in the clusters. Probably because both \n",
    "    positive and negative reviews share many common words.</strong> </p>\n",
    "    \n",
    "<p> <strong>Below we can look at some wordclouds from each cluster to see what kind of words were placed\n",
    "    in the clusters </strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.filterwarnings(\"ignore\")\n",
    "reviews_cluster_0 = reviews_class[reviews_class['cluster_num'] == 0] \n",
    "wordcloud = WordCloud(\n",
    "    width = 3000,\n",
    "    height = 2000,\n",
    "    background_color = 'black',\n",
    "    stopwords = STOPWORDS).generate(str(reviews_cluster_0))\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize = (10, 7),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.filterwarnings(\"ignore\")\n",
    "reviews_cluster_1 = reviews_class[reviews_class['cluster_num'] == 1] \n",
    "wordcloud = WordCloud(\n",
    "    width = 3000,\n",
    "    height = 2000,\n",
    "    background_color = 'black',\n",
    "    stopwords = STOPWORDS).generate(str(reviews_cluster_1))\n",
    "\n",
    "fig = plt.figure(\n",
    "    figsize = (10, 7),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong> Clustering did not provide much usefulness predicting what text would make a good\n",
    "    or bad review </strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Non-Descriptive Method - Multinomial Naive Bayes </h3>\n",
    "\n",
    "<p><strong> Naive Bayes is a popular classification algorithm for use with NLP projects and is often used in spam filtering. I     Will split the data and use 30% for training and remaining 70% for testing.</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the text of punctuation and stopwords\n",
    "def clean_text(text):\n",
    "    remove_punctuation = [word for word in text if word not in string.punctuation]\n",
    "    remove_punctuation = ''.join(remove_punctuation)\n",
    "    return [word.lower() for word in remove_punctuation.split() if word.lower() not in stopwords.words('english')]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_text)),  # strings to token integer counts\n",
    "    #('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews_class['text']\n",
    "y = reviews_class['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "labels = np.unique(y_test)\n",
    "#print(confusion_matrix(y_test,predictions, labels=labels))\n",
    "a = confusion_matrix(y_test, predictions, labels=labels)\n",
    "print(pd.DataFrame(a, index=labels, columns=labels))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.predict([\"Starbucks is trash... Why do people go to this overpriced steaming pile of garbage coffee shop. I can make some Foldgers instand blend at home that cost me .10 and tastes better.\",\n",
    "                       \"What a great resturaunt with awesome food and service\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(x):\n",
    "    review_list = []\n",
    "    review_list.append(x)\n",
    "    if pipeline.predict(review_list) == 5:\n",
    "        print('\\033[1m{:10s}\\033[0m'.format('It was a good review!'))\n",
    "        #print(\"it was a good review\")\n",
    "    else:\n",
    "       print('\\033[1m{:10s}\\033[0m'.format('It was a bad review!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interact(get_review, x = 'insert review here'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
